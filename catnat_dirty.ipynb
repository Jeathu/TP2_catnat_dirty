{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a77643e",
   "metadata": {},
   "source": [
    "# __*TP 2 - Préparation des données avec Python - Jeathusa*__\n",
    "\n",
    "## **Objectif :**\n",
    "\n",
    "Nettoyer le dataset `catnat_dirty.csv` et produire un fichier propre `catnat_clean.csv` prêt à être analysé dans Tableau.\n",
    "\n",
    "<br>\n",
    "\n",
    "## - __**Problèmes à résoudre**__\n",
    "__**Le dataset contient volontairement :**__\n",
    "\n",
    "\n",
    "- ~150 doublons\n",
    "- Valeurs manquantes supplémentaires\n",
    "- Incohérences de casse (Asia, ASIA, asia...)\n",
    "- Espaces parasites\n",
    "- Variantes d'orthographe (USA, US, United States...)\n",
    "- `Start Year` en format texte avec erreurs (\"2020 AD\", \"Year 2020\")\n",
    "- Outliers aberrants (décès négatifs, magnitude à 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dedd9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./data/raw/catnat_dirty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "adcc31ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DisNo.</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Subregion</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>No. Injured</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>No. Homeless</th>\n",
       "      <th>Total Damage ('000 US$)</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-0121-IDN</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>South-eastern Asia</td>\n",
       "      <td>FLOOD</td>\n",
       "      <td>Flood (General)</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56488.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-0524-USA</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>WILDFIRE</td>\n",
       "      <td>Wildfire (General)</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-0281-SLB</td>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Melanesia</td>\n",
       "      <td>storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Tropical cylone Raquel</td>\n",
       "      <td>2015</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-0274-KHM</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>South-eastern Asia</td>\n",
       "      <td>epidemic</td>\n",
       "      <td>Viral disease</td>\n",
       "      <td>Biological</td>\n",
       "      <td>Dengue</td>\n",
       "      <td>2007</td>\n",
       "      <td>7.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-0275-JPN</td>\n",
       "      <td>Japon</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Eastern Asia</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>39.802</td>\n",
       "      <td>141.464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DisNo.                   Country    Region           Subregion  \\\n",
       "0  2020-0121-IDN                 Indonesia     Asia   South-eastern Asia   \n",
       "1  2008-0524-USA  United States of America  Americas    Northern America   \n",
       "2  2015-0281-SLB          Solomon Islands    Oceania           Melanesia   \n",
       "3  2007-0274-KHM                 Cambodia       Asia  South-eastern Asia   \n",
       "4  2008-0275-JPN                     Japon      Asia        Eastern Asia   \n",
       "\n",
       "  Disaster Type    Disaster Subtype Disaster Subgroup              Event Name  \\\n",
       "0         FLOOD     Flood (General)      Hydrological                     NaN   \n",
       "1      WILDFIRE  Wildfire (General)    Climatological                     NaN   \n",
       "2         storm    Tropical cyclone    Meteorological  Tropical cylone Raquel   \n",
       "3      epidemic       Viral disease        Biological                  Dengue   \n",
       "4    earthquake     Ground movement       Geophysical                     NaN   \n",
       "\n",
       "  Start Year  Start Month  Total Deaths  No. Injured  Total Affected  \\\n",
       "0       2020          3.0           1.0          NaN         56488.0   \n",
       "1       2008         11.0           NaN         20.0         55020.0   \n",
       "2       2015          7.0           9.0          NaN           400.0   \n",
       "3       2007          7.0         182.0          NaN         17000.0   \n",
       "4       2008          7.0           1.0        200.0           470.0   \n",
       "\n",
       "   No. Homeless  Total Damage ('000 US$)  Magnitude  Latitude  Longitude  \n",
       "0           NaN                      NaN        NaN       NaN        NaN  \n",
       "1           NaN                2000000.0        NaN       NaN        NaN  \n",
       "2         400.0                   2000.0        NaN       NaN        NaN  \n",
       "3           NaN                      NaN        NaN       NaN        NaN  \n",
       "4           NaN                 110000.0        6.8    39.802    141.464  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef83ab0",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## __**Exercice 1 — Exploration et diagnostic**__\n",
    "\n",
    "### **Rappel**\n",
    ">\n",
    "> Avant de modifier, toujours explorer :\n",
    ">\n",
    "> - `df.shape` → dimensions\n",
    "> - `df.info()` → types et nulls\n",
    "> - `df.describe()` → statistiques\n",
    "> - `df.isnull().sum()` → comptage des nulls\n",
    "> - `df.duplicated().sum()` → comptage des doublons\n",
    "> - `df['col'].value_counts()` → valeurs uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f51e6",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### __*À faire*__\n",
    "\n",
    "1. Affichez les dimensions du dataset\n",
    "2. Affichez les types de données avec `info()`\n",
    "3. Comptez les valeurs manquantes par colonne (nombre et pourcentage)\n",
    "4. Comptez le nombre de doublons\n",
    "5. Affichez les valeurs uniques de `Region` — repérez les incohérences\n",
    "6. Affichez les statistiques de `Total Deaths` — repérez les anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac40eea",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**1. Affichez les dimensions du dataset**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1e7b787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number de lignes: 17510\n",
      "Number de la columns: 18\n"
     ]
    }
   ],
   "source": [
    "df.shape\n",
    "print(f\"Number de lignes: {df.shape[0]}\")\n",
    "print(f\"Number de la columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3875c862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>No. Injured</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>No. Homeless</th>\n",
       "      <th>Total Damage ('000 US$)</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16599.000000</td>\n",
       "      <td>1.259300e+04</td>\n",
       "      <td>4.507000e+03</td>\n",
       "      <td>1.295100e+04</td>\n",
       "      <td>2.521000e+03</td>\n",
       "      <td>5.630000e+03</td>\n",
       "      <td>5.249000e+03</td>\n",
       "      <td>2821.000000</td>\n",
       "      <td>2821.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.442798</td>\n",
       "      <td>2.751663e+03</td>\n",
       "      <td>2.538213e+03</td>\n",
       "      <td>6.873218e+05</td>\n",
       "      <td>7.226349e+04</td>\n",
       "      <td>8.448720e+05</td>\n",
       "      <td>3.780406e+04</td>\n",
       "      <td>18.587746</td>\n",
       "      <td>39.675560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.387116</td>\n",
       "      <td>6.577989e+04</td>\n",
       "      <td>3.230524e+04</td>\n",
       "      <td>7.343419e+06</td>\n",
       "      <td>5.158677e+05</td>\n",
       "      <td>5.077550e+06</td>\n",
       "      <td>2.331585e+05</td>\n",
       "      <td>21.591603</td>\n",
       "      <td>77.230791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.600000e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>-5.700000e+01</td>\n",
       "      <td>-72.640000</td>\n",
       "      <td>-178.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>5.020000e+02</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>6.900000e+00</td>\n",
       "      <td>3.295000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>6.000000e+03</td>\n",
       "      <td>3.000000e+03</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>1.400000e+02</td>\n",
       "      <td>23.027000</td>\n",
       "      <td>49.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.100000e+01</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>1.700000e+04</td>\n",
       "      <td>3.730000e+05</td>\n",
       "      <td>6.851660e+03</td>\n",
       "      <td>36.623000</td>\n",
       "      <td>102.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.700000e+06</td>\n",
       "      <td>1.800000e+06</td>\n",
       "      <td>3.300000e+08</td>\n",
       "      <td>1.585000e+07</td>\n",
       "      <td>2.100000e+08</td>\n",
       "      <td>1.302587e+07</td>\n",
       "      <td>67.930000</td>\n",
       "      <td>179.650000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Start Month  Total Deaths   No. Injured  Total Affected  No. Homeless  \\\n",
       "count  16599.000000  1.259300e+04  4.507000e+03    1.295100e+04  2.521000e+03   \n",
       "mean       6.442798  2.751663e+03  2.538213e+03    6.873218e+05  7.226349e+04   \n",
       "std        3.387116  6.577989e+04  3.230524e+04    7.343419e+06  5.158677e+05   \n",
       "min        1.000000 -3.600000e+04  1.000000e+00    1.000000e+00  3.000000e+00   \n",
       "25%        4.000000  5.000000e+00  1.300000e+01    7.000000e+02  5.020000e+02   \n",
       "50%        7.000000  1.800000e+01  5.000000e+01    6.000000e+03  3.000000e+03   \n",
       "75%        9.000000  6.100000e+01  2.000000e+02    6.000000e+04  1.700000e+04   \n",
       "max       12.000000  3.700000e+06  1.800000e+06    3.300000e+08  1.585000e+07   \n",
       "\n",
       "       Total Damage ('000 US$)     Magnitude     Latitude    Longitude  \n",
       "count             5.630000e+03  5.249000e+03  2821.000000  2821.000000  \n",
       "mean              8.448720e+05  3.780406e+04    18.587746    39.675560  \n",
       "std               5.077550e+06  2.331585e+05    21.591603    77.230791  \n",
       "min               2.000000e+00 -5.700000e+01   -72.640000  -178.252000  \n",
       "25%               1.000000e+04  6.900000e+00     3.295000     0.710000  \n",
       "50%               7.000000e+04  1.400000e+02    23.027000    49.780000  \n",
       "75%               3.730000e+05  6.851660e+03    36.623000   102.680000  \n",
       "max               2.100000e+08  1.302587e+07    67.930000   179.650000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8cfbf5",
   "metadata": {},
   "source": [
    "\n",
    "#### __**2. Affichez les types de données avec `info()`**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "89f320b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 17510 entries, 0 to 17509\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   DisNo.                   17510 non-null  str    \n",
      " 1   Country                  17510 non-null  str    \n",
      " 2   Region                   17161 non-null  str    \n",
      " 3   Subregion                17510 non-null  str    \n",
      " 4   Disaster Type            17510 non-null  str    \n",
      " 5   Disaster Subtype         17510 non-null  str    \n",
      " 6   Disaster Subgroup        17510 non-null  str    \n",
      " 7   Event Name               3975 non-null   str    \n",
      " 8   Start Year               17510 non-null  str    \n",
      " 9   Start Month              16599 non-null  float64\n",
      " 10  Total Deaths             12593 non-null  float64\n",
      " 11  No. Injured              4507 non-null   float64\n",
      " 12  Total Affected           12951 non-null  float64\n",
      " 13  No. Homeless             2521 non-null   float64\n",
      " 14  Total Damage ('000 US$)  5630 non-null   float64\n",
      " 15  Magnitude                5249 non-null   float64\n",
      " 16  Latitude                 2821 non-null   float64\n",
      " 17  Longitude                2821 non-null   float64\n",
      "dtypes: float64(9), str(9)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46abd907",
   "metadata": {},
   "source": [
    "\n",
    "#### __**3. Comptez les valeurs manquantes par colonne (nombre et pourcentage)**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2daa0a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Manquant Pourcentage\n",
      "DisNo.                          0        0.0%\n",
      "Country                         0        0.0%\n",
      "Region                        349       1.99%\n",
      "Subregion                       0        0.0%\n",
      "Disaster Type                   0        0.0%\n",
      "Disaster Subtype                0        0.0%\n",
      "Disaster Subgroup               0        0.0%\n",
      "Event Name                  13535       77.3%\n",
      "Start Year                      0        0.0%\n",
      "Start Month                   911        5.2%\n",
      "Total Deaths                 4917      28.08%\n",
      "No. Injured                 13003      74.26%\n",
      "Total Affected               4559      26.04%\n",
      "No. Homeless                14989       85.6%\n",
      "Total Damage ('000 US$)     11880      67.85%\n",
      "Magnitude                   12261      70.02%\n",
      "Latitude                    14689      83.89%\n",
      "Longitude                   14689      83.89%\n"
     ]
    }
   ],
   "source": [
    "manquant = df.isnull().sum()\n",
    "manquant_pourcentage = (manquant / len(df)) * 100\n",
    "manquant_df = pd.DataFrame({\"Manquant\": manquant, \"Pourcentage\": manquant_pourcentage})\n",
    "manquant_df[\"Pourcentage\"] = manquant_df[\"Pourcentage\"].round(2).astype(str) + \"%\"\n",
    "print(manquant_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd4474",
   "metadata": {},
   "source": [
    "#### __**4. Comptez le nombre de doublons**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "20adfb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons : 150\n"
     ]
    }
   ],
   "source": [
    "n_doublons = df.duplicated().sum()\n",
    "print(f\"Nombre de doublons : {n_doublons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef2ea4",
   "metadata": {},
   "source": [
    "#### __**5. Affichez les valeurs uniques de `Region` - repérez les incohérences**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eead7f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs uniques (brutes):\n",
      "<StringArray>\n",
      "[     'Asia ',   'Americas',    'Oceania',       'Asia',       'ASIA',\n",
      " ' Americas ',     'Africa',    'Europe ',     'Europe',  ' Americas',\n",
      "     'EUROPE',  'AMERICAS ',   'americas',   'AMERICAS',     ' Asia ',\n",
      "    ' Africa',  'Americas ',       'asia',   ' Oceania',      'ASIA ',\n",
      "    'oceania', ' americas ',      ' Asia',      'asia ',    'OCEANIA',\n",
      "     'africa',     'AFRICA',     'europe',    'europe ', ' AMERICAS ',\n",
      "  'americas ',  ' AMERICAS',   ' Europe ',    ' EUROPE',      ' ASIA',\n",
      "   ' Africa ',  ' americas',    'africa ',      ' asia',    ' africa',\n",
      "   ' AFRICA ',    'Africa ',    ' AFRICA',   'Oceania ',     ' asia ',\n",
      "    'AFRICA ',   ' europe ',    'EUROPE ',    ' Europe',   ' africa ',\n",
      "     ' ASIA ',    ' europe',  ' Oceania ',   'OCEANIA ',  ' OCEANIA ',\n",
      "   ' EUROPE ',   'oceania ',   ' OCEANIA',  ' oceania ',   ' oceania']\n",
      "Length: 60, dtype: str\n"
     ]
    }
   ],
   "source": [
    "raw_unique = df['Region'].dropna().unique()\n",
    "print(\"Valeurs uniques (brutes):\")\n",
    "print(raw_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e3056162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comptage brut:\n",
      "\n",
      "Region\n",
      "Asia         3754\n",
      "Americas     2359\n",
      "Africa       1688\n",
      "Europe       1201\n",
      "ASIA          792\n",
      "             ... \n",
      "OCEANIA         8\n",
      " OCEANIA        7\n",
      " oceania        7\n",
      " OCEANIA        5\n",
      " oceania        5\n",
      "Name: count, Length: 61, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComptage brut:\\n\")\n",
    "print(df['Region'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf501e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__**`- J'ai fait test sur les variantes sur la colonne Region pour montrer les incohérences (espaces, casse, orthographe).`**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4639a98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compte (normalisé: strip + lower):\n",
      "Region\n",
      "asia        6881\n",
      "americas    4283\n",
      "africa      3169\n",
      "europe      2131\n",
      "oceania      697\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "norm = df['Region'].astype(str).str.strip().str.lower()\n",
    "print(\"\\nCompte (normalisé: strip + lower):\")\n",
    "print(norm.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004c08c",
   "metadata": {},
   "source": [
    "#### __**6. Affichez les statistiques de `Total Deaths` - repérez les anomalies**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5511964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistiques descriptives pour 'Total Deaths':\n",
      "\n",
      "count    1.259300e+04\n",
      "mean     2.751663e+03\n",
      "std      6.577989e+04\n",
      "min     -3.600000e+04\n",
      "25%      5.000000e+00\n",
      "50%      1.800000e+01\n",
      "75%      6.100000e+01\n",
      "max      3.700000e+06\n",
      "Name: Total Deaths, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "totale_mort = df['Total Deaths'].describe()\n",
    "\n",
    "print(\"\\nStatistiques descriptives pour 'Total Deaths':\\n\")\n",
    "print(totale_mort)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d5e20",
   "metadata": {},
   "source": [
    " __**`- Comme on peut voir les valeurs min est -3.600000e+04, ce qui est anormal.`**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "faf70ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de négatifs:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67\n",
      "\n",
      "Exemples de valeurs négatives:\n",
      "        Region  Total Deaths\n",
      "33   Americas          -2.0\n",
      "136    Africa         -30.0\n",
      "293      Asia          -1.0\n",
      "607     Asia          -21.0\n",
      "754  Americas         -61.0\n"
     ]
    }
   ],
   "source": [
    "# Valeurs négatives dans 'Total Deaths'\n",
    "neg = df[df['Total Deaths'] < 0]\n",
    "print(\"\\nNombre de négatifs:\", len(neg))\n",
    "print(\"\\nExemples de valeurs négatives:\\n\", neg[['Region', 'Total Deaths']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537cb93",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## __**Questions**__\n",
    "\n",
    "**1. Combien y a-t-il de doublons ?**\n",
    "\n",
    "* D'Après le résultat de `df.duplicated().sum()`, il y a 150 doublons dans le dataset.    \n",
    "Le dataset contient 17510 lignes, 18 colonnes.\n",
    "\n",
    "<br>\n",
    "\n",
    "**2. Quelles colonnes ont le plus de valeurs manquantes ?**\n",
    "\n",
    "* D'Après le résultat de `manquant = df.isnull().sum()`, les colonnes avec le plus de valeurs manquantes sont :\n",
    "* No. Homeless                14989     -   (85.6%)\n",
    "* Latitude                    14689   -    (83.89%)\n",
    "* Longitude                   14689   -    (83.89%)\n",
    "* Event Name                  13535    -    (77.3%)\n",
    "* No. Injured                 13003   -    (74.26%)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**3. Combien de variantes différentes pour \"Asia\" ?**\n",
    "* D'Après le résultat de `df['Region'].value_counts()`, il y a 3 variantes différentes pour \"Asia\" : \"Asia\", \"ASIA\", \"asia\" qui représentent respectivement 3754 occurences.\n",
    "\n",
    "<br>\n",
    "\n",
    "**4. Y a-t-il des valeurs négatives dans `Total Deaths` ?**\n",
    "* D'Après le résultat de `df['Total Deaths'].describe()`, il y a des valeurs négatives dans `Total Deaths` avec une valeur minimum de -36000, ce qui est anormal pour ce type de données.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe664a6",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "## __**Exercice 2 — Suppression des doublons**__\n",
    "\n",
    "> **Rappel**\n",
    ">\n",
    "> ```python\n",
    "> # Identifier les doublons\n",
    "> df[df.duplicated()]\n",
    "> df[df.duplicated(keep=False)]  # Inclut les originaux\n",
    ">\n",
    "> # Supprimer les doublons\n",
    "> df = df.drop_duplicates()\n",
    "> df = df.drop_duplicates(subset=['col1', 'col2'])  # Sur certaines colonnes\n",
    "> ```\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### __*À faire*__\n",
    "\n",
    "1. Affichez quelques lignes dupliquées pour vérifier\n",
    "2. Supprimez les doublons exacts\n",
    "3. Vérifiez que les doublons ont bien été supprimés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe1e59a",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "#### __**1. Affichez quelques lignes dupliquées pour vérifier**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "15e87a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DisNo.</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Subregion</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>No. Injured</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>No. Homeless</th>\n",
       "      <th>Total Damage ('000 US$)</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1969-0071-IND</td>\n",
       "      <td>India</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1969</td>\n",
       "      <td>5.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8330.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2005-0583-USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>americas</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Riverine flood</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38290.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1963-0055-BEL</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Extreme Temperature</td>\n",
       "      <td>Cold wave</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2023-0510-MNG</td>\n",
       "      <td>Mongolia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Eastern Asia</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Flash flood</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1996-0226-CHN</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Eastern Asia</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Willie</td>\n",
       "      <td>1996</td>\n",
       "      <td>9.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>130.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>2023-0290-SLE</td>\n",
       "      <td>Sierra Leone</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>STORM</td>\n",
       "      <td>Storm (General)</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17228</th>\n",
       "      <td>1997-0126-SLV</td>\n",
       "      <td>El Salvador</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Latin America and the Caribbean</td>\n",
       "      <td>STORM</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Andres</td>\n",
       "      <td>1997</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17339</th>\n",
       "      <td>2010-0053-PAK</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Riverine flood</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17410</th>\n",
       "      <td>2013-0286-USA</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Riverine flood</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>33907.85</td>\n",
       "      <td>28.8990</td>\n",
       "      <td>-98.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17413</th>\n",
       "      <td>2015-0226-IND</td>\n",
       "      <td>India</td>\n",
       "      <td>asia</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>Mass movement (wet)</td>\n",
       "      <td>Landslide (wet)</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.9195</td>\n",
       "      <td>93.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DisNo.                    Country    Region  \\\n",
       "27     1969-0071-IND                      India      ASIA   \n",
       "125    2005-0583-USA                        USA  americas   \n",
       "322    1963-0055-BEL                    Belgium    Europe   \n",
       "371    2023-0510-MNG                   Mongolia      Asia   \n",
       "456    1996-0226-CHN                      China      Asia   \n",
       "...              ...                        ...       ...   \n",
       "17194  2023-0290-SLE               Sierra Leone    Africa   \n",
       "17228  1997-0126-SLV                El Salvador  Americas   \n",
       "17339  2010-0053-PAK                   Pakistan      ASIA   \n",
       "17410  2013-0286-USA   United States of America  Americas   \n",
       "17413  2015-0226-IND                      India     asia    \n",
       "\n",
       "                             Subregion        Disaster Type  Disaster Subtype  \\\n",
       "27                       Southern Asia                Storm  Tropical cyclone   \n",
       "125                   Northern America                Flood    Riverine flood   \n",
       "322                     Western Europe  Extreme Temperature         Cold wave   \n",
       "371                       Eastern Asia                Flood       Flash flood   \n",
       "456                       Eastern Asia                Storm  Tropical cyclone   \n",
       "...                                ...                  ...               ...   \n",
       "17194               Sub-Saharan Africa                STORM   Storm (General)   \n",
       "17228  Latin America and the Caribbean                STORM  Tropical cyclone   \n",
       "17339                    Southern Asia                Flood    Riverine flood   \n",
       "17410                 Northern America                Flood    Riverine flood   \n",
       "17413                    Southern Asia  Mass movement (wet)   Landslide (wet)   \n",
       "\n",
       "      Disaster Subgroup Event Name Start Year  Start Month  Total Deaths  \\\n",
       "27       Meteorological        NaN       1969          5.0      600000.0   \n",
       "125        Hydrological        NaN       2005         10.0          11.0   \n",
       "322      Meteorological        NaN       1963          NaN          12.0   \n",
       "371        Hydrological        NaN       2023          8.0           4.0   \n",
       "456      Meteorological     Willie       1996          9.0          38.0   \n",
       "...                 ...        ...        ...          ...           ...   \n",
       "17194    Meteorological        NaN       2023          5.0          15.0   \n",
       "17228    Meteorological     Andres       1997          6.0           4.0   \n",
       "17339      Hydrological        NaN       2010          2.0          22.0   \n",
       "17410      Hydrological        NaN       2013          5.0           3.0   \n",
       "17413      Hydrological        NaN       2015          6.0           3.0   \n",
       "\n",
       "       No. Injured  Total Affected  No. Homeless  Total Damage ('000 US$)  \\\n",
       "27             NaN        260000.0           NaN                   8330.0   \n",
       "125            NaN          3000.0           NaN                      NaN   \n",
       "322            NaN             NaN           NaN                      NaN   \n",
       "371            NaN          1230.0           NaN                      NaN   \n",
       "456            NaN             NaN           NaN                 100000.0   \n",
       "...            ...             ...           ...                      ...   \n",
       "17194         17.0            17.0           NaN                      NaN   \n",
       "17228          NaN          2000.0        2000.0                      NaN   \n",
       "17339          NaN             NaN           NaN                      NaN   \n",
       "17410          NaN           300.0           NaN                   2000.0   \n",
       "17413          NaN          9000.0           NaN                      NaN   \n",
       "\n",
       "       Magnitude  Latitude  Longitude  \n",
       "27           NaN       NaN        NaN  \n",
       "125     38290.00       NaN        NaN  \n",
       "322       -22.00       NaN        NaN  \n",
       "371          NaN       NaN        NaN  \n",
       "456       130.00       NaN        NaN  \n",
       "...          ...       ...        ...  \n",
       "17194        NaN       NaN        NaN  \n",
       "17228        NaN       NaN        NaN  \n",
       "17339        NaN       NaN        NaN  \n",
       "17410   33907.85   28.8990     -98.89  \n",
       "17413        NaN   26.9195      93.87  \n",
       "\n",
       "[300 rows x 18 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e82331",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**2. Supprimez les doublons exacts**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "218d1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b4052b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**3. Vérifiez que les doublons ont bien été supprimés**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "152b6c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons : 0\n"
     ]
    }
   ],
   "source": [
    "n_doublons = df.duplicated().sum()\n",
    "print(f\"Nombre de doublons : {n_doublons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d1416",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "## __**Exercice 3 — Correction des types**__\n",
    "\n",
    "> **Rappel**\n",
    ">\n",
    "> ```python\n",
    "> # Vérifier les types\n",
    "> df.dtypes\n",
    ">\n",
    "> # Convertir en numérique (erreurs → NaN)\n",
    "> df['col'] = pd.to_numeric(df['col'], errors='coerce')\n",
    ">\n",
    "> # Convertir en entier\n",
    "> df['col'] = df['col'].astype(int)\n",
    ">\n",
    "> # Convertir en date\n",
    "> df['col'] = pd.to_datetime(df['col'], errors='coerce')\n",
    "> ```\n",
    "\n",
    "```python\n",
    "# petit hint...\n",
    "dtype.name existe !\n",
    "\n",
    "# AD signifie Anno Domini, elle correspond à la formule français après JC ...\n",
    "```\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### __*À faire*__\n",
    "\n",
    "1. Vérifiez le type de `Start Year`\n",
    "2. Affichez quelques valeurs problématiques (contenant \"Year\" ou \"AD\")\n",
    "3. Nettoyez la colonne : supprimez le texte et convertissez en numérique\n",
    "4. Vérifiez le résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fdc385",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**1. Vérifiez le type de `Start Year`**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "85fe5419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type de la colonne 'Start Year': str\n"
     ]
    }
   ],
   "source": [
    "print(f\"Type de la colonne 'Start Year': {df['Start Year'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b94e5d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**2. Affichez quelques valeurs problématiques (contenant \"Year\" ou \"AD\")**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6d91a46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de valeurs problématiques :\n",
      "    Start Year\n",
      "26     1982 AD\n",
      "138  Year 2012\n",
      "480    2021 AD\n",
      "506  Year 2017\n",
      "634  Year 2003\n"
     ]
    }
   ],
   "source": [
    "valeurs_problematiques = df[df['Start Year'].astype(str).str.contains(\"Year|AD\", na=False)]\n",
    "print(\"Exemples de valeurs problématiques :\")\n",
    "print(valeurs_problematiques[['Start Year']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458a84c",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**3. Nettoyez la colonne : supprimez le texte et convertissez en numérique**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "99e92524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les text chaînes de caractères \"Year\" et \"AD\"\n",
    "df['Start Year'] = df['Start Year'].astype(str).str.replace(r'Year|AD', '', regex=True).str.strip()\n",
    "\n",
    "# Convertir la colonne en numérique\n",
    "df['Start Year'] = pd.to_numeric(df['Start Year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e94a60",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**4. Vérifiez le résultat**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "950516e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveau type de la colonne 'Start Year': int64\n",
      "Nombre de valeurs textuelles restantes : 0\n",
      "\n",
      "Valeurs de la colonne nettoyée :\n",
      "0    2020\n",
      "1    2008\n",
      "2    2015\n",
      "3    2007\n",
      "4    2008\n",
      "Name: Start Year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nouveau type de la colonne 'Start Year': {df['Start Year'].dtype}\")\n",
    "\n",
    "# Vérification des valeurs textuelles restantes\n",
    "valeurs_texte_restantes = df['Start Year'].apply(lambda x: isinstance(x, str)).sum()\n",
    "print(f\"Nombre de valeurs textuelles restantes : {valeurs_texte_restantes}\")\n",
    "\n",
    "print(\"\\nValeurs de la colonne nettoyée :\")\n",
    "print(df['Start Year'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4353bb4c",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "## __**Exercice 4 — Traitement des valeurs manquantes**__\n",
    "\n",
    "> **Rappel**\n",
    ">\n",
    "> | Situation                               | Action                             |\n",
    "> | --------------------------------------- | ---------------------------------- |\n",
    "> | Peu de nulls, colonne critique          | Supprimer les lignes               |\n",
    "> | Beaucoup de nulls, colonne non critique | Supprimer la colonne ou garder NaN |\n",
    "> | Numérique, distribution asymétrique     | Imputer par médiane                |\n",
    "> | Catégoriel                              | Imputer par mode ou \"Inconnu\"      |\n",
    ">\n",
    "> ```python\n",
    "> df.dropna(subset=['col'])           # Supprimer lignes\n",
    "> df['col'].fillna(valeur)            # Remplacer\n",
    "> df['col'].fillna(df['col'].median())  # Médiane\n",
    "> ```\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### __**À faire**__\n",
    "\n",
    "1. Pour `Region` (peu de nulls) : supprimez les lignes avec null\n",
    "2. Pour `Event Name` : remplacez les nulls par \"Non nommé\"\n",
    "3. Pour `Total Deaths` : décidez d'une stratégie et appliquez-la\n",
    "4. Pour `Magnitude` : laissez les nulls (n'a pas de sens pour tous les types)\n",
    "5. Vérifiez le résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3961fed",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**1. Pour `Region` (peu de nulls) : supprimez les lignes avec null**__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9fc9c10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes dans 'Region': 17360\n",
      "Nuls dans 'Region' : 346\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Nombre de lignes dans 'Region': {len(df)}\")\n",
    "print(f\"Nuls dans 'Region' : {df['Region'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c2cb55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des lignes où Region est nulle\n",
    "df.dropna(subset=['Region'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b9b993ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes après suppression: 17014\n",
      "Nuls dans 'Region' après: 0\n"
     ]
    }
   ],
   "source": [
    "# Après la suppression\n",
    "print(f\"Nombre de lignes après suppression: {len(df)}\")\n",
    "print(f\"Nuls dans 'Region' après: {df['Region'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f95fb",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**2. Pour `Event Name` : remplacez les nulls par \"Non nommé\"**__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "367a0620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeath\\AppData\\Local\\Temp\\ipykernel_17288\\3554683477.py:1: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.\n",
      "\n",
      "See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html\n",
      "  df['Event Name'].fillna('Non nommé', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                       Non nommé\n",
       "1                       Non nommé\n",
       "2          Tropical cylone Raquel\n",
       "3                          Dengue\n",
       "4                       Non nommé\n",
       "                   ...           \n",
       "17505                   Non nommé\n",
       "17506     Tropical storm \"Emily\" \n",
       "17507                   Non nommé\n",
       "17508                   Non nommé\n",
       "17509                   Non nommé\n",
       "Name: Event Name, Length: 17014, dtype: str"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Event Name'].fillna('Non nommé', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756cb93d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**3. Pour `Total Deaths` : décidez d'une stratégie et appliquez-la**__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "432d00e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La médiane des décès est : 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeath\\AppData\\Local\\Temp\\ipykernel_17288\\736382464.py:6: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.\n",
      "\n",
      "See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html\n",
      "  df['Total Deaths'].fillna(median_deaths, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          1.0\n",
       "1         18.0\n",
       "2          9.0\n",
       "3        182.0\n",
       "4          1.0\n",
       "         ...  \n",
       "17505     18.0\n",
       "17506      3.0\n",
       "17507      7.0\n",
       "17508     50.0\n",
       "17509     12.0\n",
       "Name: Total Deaths, Length: 17014, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculer la médiane des décès\n",
    "median_deaths = df['Total Deaths'].median()\n",
    "print(f\"La médiane des décès est : {median_deaths}\")\n",
    "\n",
    "# Remplacer les nuls par la médiane\n",
    "df['Total Deaths'].fillna(median_deaths, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386a422",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**4. Pour `Magnitude` : laissez les nulls (n'a pas de sens pour tous les types)**__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7ac63464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(df['Magnitude'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "96ee36dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls: 11929/17014 (70.11%)\n",
      "Magnitude\n",
      "NaN      11929\n",
      "100.0       85\n",
      "120.0       67\n",
      "6.0         66\n",
      "150.0       66\n",
      "6.3         66\n",
      "6.4         65\n",
      "6.5         63\n",
      "5.6         63\n",
      "130.0       63\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n_null = df['Magnitude'].isnull().sum()\n",
    "print(f\"Nulls: {n_null}/{len(df)} ({n_null/len(df)*100:.2f}%)\")\n",
    "print(df['Magnitude'].value_counts(dropna=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "edbf96e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    5.085000e+03\n",
      "mean     3.788548e+04\n",
      "std      2.355306e+05\n",
      "min     -5.700000e+01\n",
      "25%      6.900000e+00\n",
      "50%      1.400000e+02\n",
      "75%      6.800000e+03\n",
      "max      1.302587e+07\n",
      "Name: Magnitude, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mag_num = pd.to_numeric(df['Magnitude'], errors='coerce')\n",
    "print(mag_num.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04776d1",
   "metadata": {},
   "source": [
    "__**`- Je l’ai laissé en `NaN` car, à mon avis personnel, la magnitude n’est pas pertinente pour tous les types d’événements, imputer une valeur introduirait une fausse précision. Cette décision est documentée et on peut ajouter une colonne indicatrice (`exemple:  has_magnitude;`) ou traiter séparément les événements avec magnitude.`**__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff0f375",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**5. Vérifiez le résultat**__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1112cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs manquantes par colonne après traitement :\n",
      "DisNo.                         0\n",
      "Country                        0\n",
      "Region                         0\n",
      "Subregion                      0\n",
      "Disaster Type                  0\n",
      "Disaster Subtype               0\n",
      "Disaster Subgroup              0\n",
      "Event Name                 13139\n",
      "Start Year                     0\n",
      "Start Month                  890\n",
      "Total Deaths                4774\n",
      "No. Injured                12643\n",
      "Total Affected              4441\n",
      "No. Homeless               14570\n",
      "Total Damage ('000 US$)    11540\n",
      "Magnitude                  11929\n",
      "Latitude                   14289\n",
      "Longitude                  14289\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de valeurs manquantes par colonne après traitement :\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5d4388",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "## __**Exercice 5 — Traitement des outliers**__\n",
    "\n",
    "> **Rappel**\n",
    ">\n",
    "> Deux questions :\n",
    ">\n",
    "> 1. Est-ce une erreur ? → Corriger ou supprimer\n",
    "> 2. Est-ce une valeur extrême réelle ? → Garder (ou analyser séparément)\n",
    ">\n",
    "> ```python\n",
    "> # Valeurs impossibles\n",
    "> df[df['col'] < 0]\n",
    "> df[df['col'] > seuil_max]\n",
    ">\n",
    "> # Supprimer\n",
    "> df = df[df['col'] >= 0]\n",
    ">\n",
    "> # Capper\n",
    "> df['col'] = df['col'].clip(lower=0, upper=max_val)\n",
    "> ```\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### __*À faire*__\n",
    "\n",
    "1. Identifiez les valeurs négatives dans `Total Deaths`\n",
    "2. Identifiez les valeurs aberrantes dans `Magnitude` (> 10)\n",
    "3. Décidez : supprimer ou corriger ?\n",
    "4. Appliquez le traitement\n",
    "5. Vérifiez le résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac2138",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**1. Identifiez les valeurs négatives dans `Total Deaths`**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ced3b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "    Event Name    Region  Total Deaths\n",
      "33     Isidore  Americas          -2.0\n",
      "136        NaN    Africa         -30.0\n",
      "293        NaN      Asia          -1.0\n",
      "607        NaN     Asia          -21.0\n",
      "754        NaN  Americas         -61.0\n"
     ]
    }
   ],
   "source": [
    "print((df['Total Deaths'] < 0).sum())\n",
    "print(df[df['Total Deaths'] < 0][['Event Name','Region','Total Deaths']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aabd70",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**2. Identifiez les valeurs aberrantes dans `Magnitude` (> 10)`**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e26db576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3364\n",
      "   Disaster Type Event Name  Magnitude\n",
      "5          flood        NaN   365800.0\n",
      "32         Flood        NaN      200.0\n",
      "34      Wildfire        NaN     1320.0\n",
      "40         Flood        NaN   444500.0\n",
      "42         STORM        NaN      180.0\n"
     ]
    }
   ],
   "source": [
    "mag = pd.to_numeric(df['Magnitude'], errors='coerce')\n",
    "print((mag > 10).sum())\n",
    "print(df[mag > 10][['Disaster Type','Event Name','Magnitude']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c56f6",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**3. Décidez : supprimer ou corriger ?**__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a27b4",
   "metadata": {},
   "source": [
    "**Décès négatifs :**\n",
    "Ces valeurs sont mathématiquement et logiquement impossibles (on ne peut pas avoir un nombre de morts négatif). Il s'agit clairement d'erreurs de saisie. `Plutôt que de supprimer ces lignes et perdre d'autres informations utiles (région, type de catastrophe, magnitude), j'ai choisi de les remplacer par NaN`, puis de les imputer avec la médiane. La médiane est préférable à la moyenne car elle est robuste aux valeurs extrêmes et ne distorsionne pas la distribution des données en cas de valeurs aberrantes.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Magnitudes > 10 ou = 999 :**\n",
    "Une magnitude supérieure à 10 est physiquement impossible. La valeur 999 est clairement un code d'erreur. Ces données sont inutilisables pour l'analyse. Cependant, `j'ai remplacé ces valeurs par NaN plutôt que de supprimer les lignes entières, car les autres variables (région, date, nombre de morts) restent valides et exploitables`. Cela maximise la rétention d'informations tout en garantissant la qualité de l'analyse.\n",
    "\n",
    "<br>\n",
    "\n",
    "`En résumé : Ces choix visent à concilier qualité des données et conservation d'informations utiles.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff54904a",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**4. Appliquez le traitement**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "335da606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Décès négatifs détectés : 65\n",
      "Imputés avec la médiane : 18.0\n",
      "Décès négatifs restants : 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeath\\AppData\\Local\\Temp\\ipykernel_17288\\2847685292.py:7: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.\n",
      "\n",
      "See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html\n",
      "  df['Total Deaths'].fillna(median_deaths, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Identification et remplacement les décès négatifs par NaN\n",
    "print(\"Décès négatifs détectés :\", (df['Total Deaths'] < 0).sum())\n",
    "df.loc[df['Total Deaths'] < 0, 'Total Deaths'] = np.nan\n",
    "\n",
    "# Imputer avec la médiane\n",
    "median_deaths = df['Total Deaths'].median()\n",
    "df['Total Deaths'].fillna(median_deaths, inplace=True)\n",
    "print(f\"Imputés avec la médiane : {median_deaths}\")\n",
    "print(f\"Décès négatifs restants : {(df['Total Deaths'] < 0).sum()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e1fa86fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnitudes > 10 détectées : 3364\n",
      "Magnitudes == 999 détectées : 22\n",
      "Magnitudes invalides remplacées par NaN\n",
      "Magnitudes > 10 restantes : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mag = pd.to_numeric(df['Magnitude'], errors='coerce')\n",
    "\n",
    "# Identifier les magnitudes > 10 ou == 999\n",
    "print(\"Magnitudes > 10 détectées :\", (mag > 10).sum())\n",
    "print(\"Magnitudes == 999 détectées :\", (df['Magnitude'] == 999).sum())\n",
    "\n",
    "# Remplacement par NaN\n",
    "df.loc[(mag > 10) | (df['Magnitude'] == 999), 'Magnitude'] = np.nan\n",
    "\n",
    "print(f\"Magnitudes invalides remplacées par NaN\")\n",
    "print(f\"Magnitudes > 10 restantes : {(pd.to_numeric(df['Magnitude'], errors='coerce') > 10).sum()}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c3657",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**5. Vérifiez le résultat**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "01b6a082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "État final du dataset :\n",
      "Décès manquants (NaN) : 4839\n",
      "Magnitudes manquantes (NaN) : 15293\n",
      "Forme du dataset : (17014, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"État final du dataset :\")\n",
    "print(f\"Décès manquants (NaN) : {df['Total Deaths'].isna().sum()}\")\n",
    "print(f\"Magnitudes manquantes (NaN) : {df['Magnitude'].isna().sum()}\")\n",
    "print(f\"Forme du dataset : {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75d96a",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "## __**Exercice 6 — Nettoyage du texte**__\n",
    "\n",
    "> **Rappel**\n",
    ">\n",
    "> ```python\n",
    "> # Casse\n",
    "> df['col'].str.lower()\n",
    "> df['col'].str.upper()\n",
    "> df['col'].str.title()\n",
    ">\n",
    "> # Espaces\n",
    "> df['col'].str.strip()\n",
    ">\n",
    "> # Remplacement\n",
    "> df['col'].replace({'old': 'new'})\n",
    ">\n",
    "> # Pipeline complet\n",
    "> df['col'] = df['col'].str.strip().str.lower()\n",
    "> ```\n",
    "\n",
    "### __*À faire*__\n",
    "\n",
    "1. Nettoyez `Region` : strip + title case\n",
    "2. Vérifiez avec `value_counts()` — combien de catégories maintenant ?\n",
    "3. Nettoyez `Disaster Type` de la même manière\n",
    "4. Nettoyez `Country` : strip + title case\n",
    "5. Corrigez les variantes de pays (USA → United States, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb60958",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**1. Nettoyez `Region` : strip + title case**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0820e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Region'] = df['Region'].astype(str).str.strip().str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25d80b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**2. Vérifiez avec `value_counts()` — combien de catégories maintenant ?**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "19976865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region\n",
      "Asia        6817\n",
      "Americas    4243\n",
      "Africa      3142\n",
      "Europe      2117\n",
      "Oceania      695\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Region après nettoyage :\n",
      "Nombre de catégories uniques : 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df['Region'].value_counts())\n",
    "print(\"\\n\\nRegion après nettoyage :\")\n",
    "print(f\"Nombre de catégories uniques : {df['Region'].nunique()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a6fcb",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**3. Nettoyez `Disaster Type` de la même manière**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2665f71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disaster Type\n",
      "Flood                  5945\n",
      "Storm                  4790\n",
      "Earthquake             1584\n",
      "Epidemic               1488\n",
      "Mass Movement (Wet)     836\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Disaster Type'] = df['Disaster Type'].astype(str).str.strip().str.title()\n",
    "print(df['Disaster Type'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1799525",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**4. Nettoyez `Country` : strip + title case**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1df6e1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "United States Of America    906\n",
      "China                       854\n",
      "India                       711\n",
      "Indonesia                   560\n",
      "Philippines                 559\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Country'] = df['Country'].fillna('').astype(str).str.strip().replace('', np.nan).str.title()\n",
    "print(df['Country'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1b927",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**5. Corrigez les variantes de pays (USA → United States, etc.)**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e4db3e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'] = df['Country'].str.replace('Usa', 'United States')\n",
    "df['Country'] = df['Country'].str.replace('Us', 'United States') \n",
    "df['Country'] = df['Country'].str.replace('Uk', 'United Kingdom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4042c348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Après correction :\n",
      "Country\n",
      "United States Of America    906\n",
      "China                       854\n",
      "India                       711\n",
      "Indonesia                   560\n",
      "Philippines                 559\n",
      "Japan                       347\n",
      "Mexico                      298\n",
      "Bangladesh                  283\n",
      "Pakistan                    257\n",
      "Viet Nam                    256\n",
      "Name: count, dtype: int64\n",
      "Nombre de pays : 287\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAprès correction :\")\n",
    "print(df['Country'].value_counts().head(10))\n",
    "print(f\"Nombre de pays : {df['Country'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5d628",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "\n",
    "## __**Exercice 7 — Création de colonnes utiles**__\n",
    "\n",
    "> **Rappel**\n",
    ">\n",
    "> ```python\n",
    "> # Nouvelle colonne calculée\n",
    "> df['new'] = df['col1'] / df['col2']\n",
    ">\n",
    "> # Colonne à partir d'une autre\n",
    "> df['Decennie'] = (df['Year'] // 10) * 10\n",
    ">\n",
    "> # Extraction de date\n",
    "> df['Annee'] = df['Date'].dt.year\n",
    "> df['Mois'] = df['Date'].dt.month\n",
    "> ```\n",
    "\n",
    "### __*À faire*__\n",
    "\n",
    "1. Créez une colonne `Decennie` à partir de `Start Year`\n",
    "2. Créez une colonne `Has_Deaths` (booléen : True si Total Deaths > 0)\n",
    "3. Vérifiez vos nouvelles colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0859ee4",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**1. Créez une colonne `Decennie` à partir de `Start Year`**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c93fbe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Start Year  Decennie\n",
      "0        2020      2020\n",
      "1        2008      2000\n",
      "2        2015      2010\n",
      "3        2007      2000\n",
      "4        2008      2000\n"
     ]
    }
   ],
   "source": [
    "df['Decennie'] = (df['Start Year'] // 10) * 10\n",
    "print(df[['Start Year', 'Decennie']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b606639",
   "metadata": {},
   "source": [
    "-   ` df['Start Year'] // 10` : Division entière par 10 (enlève le dernier chiffre)\n",
    "-   Exemple : `2005 ---> 200`, `1995 ---> 199`\n",
    "-   `*10` : Multiplie par 10 pour obtenir la décennie\n",
    "-   Exemple : 200 * 10 = 2000, 199 * 10 = 1990\n",
    "\n",
    "**Résultat** : Regroupe les années par décennie (`2000-2009, 1990-1999, etc.....`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a52e43",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**2. Créez une colonne `Has_Deaths` (booléen : True si Total Deaths > 0)**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "513326d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total Deaths  Has_Deaths\n",
      "0           1.0        True\n",
      "1           NaN       False\n",
      "2           9.0        True\n",
      "3         182.0        True\n",
      "4           1.0        True\n"
     ]
    }
   ],
   "source": [
    "df['Has_Deaths'] = df['Total Deaths'] > 0\n",
    "print(df[['Total Deaths', 'Has_Deaths']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046623b",
   "metadata": {},
   "source": [
    "\n",
    "-   **Résultat** :\n",
    "-   `True` si Total Deaths > 0 (`il y a eu des décès`)\n",
    "-   `False` si Total Deaths = 0 (`pas de décès`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a58c3b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**3. Vérifiez vos nouvelles colonnes**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6669cbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Start Year  Decennie  Total Deaths  Has_Deaths\n",
      "0        2020      2020           1.0        True\n",
      "1        2008      2000           NaN       False\n",
      "2        2015      2010           9.0        True\n",
      "3        2007      2000         182.0        True\n",
      "4        2008      2000           1.0        True\n",
      "5        1997      1990          16.0        True\n",
      "6        1999      1990         325.0        True\n",
      "7        2004      2000           NaN       False\n",
      "8        1961      1960         275.0        True\n",
      "9        1914      1910          34.0        True\n",
      "\n",
      "Data types:\n",
      "Decennie      int64\n",
      "Has_Deaths     bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[['Start Year', 'Decennie', 'Total Deaths', 'Has_Deaths']].head(10))\n",
    "print(\"\\nData types:\")\n",
    "print(df[['Decennie', 'Has_Deaths']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1027a95e",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "## __**Exercice 8 — Sélection et export**__\n",
    "\n",
    "> **Rappel**\n",
    ">\n",
    "> ```python\n",
    "> # Sélectionner des colonnes\n",
    "> df_export = df[['col1', 'col2', 'col3']]\n",
    ">\n",
    "> # Renommer\n",
    "> df_export = df_export.rename(columns={'old': 'new'})\n",
    ">\n",
    "> # Export\n",
    "> df_export.to_csv(\"fichier.csv\", index=False)\n",
    "> ```\n",
    "\n",
    "## __*À faire*__\n",
    "\n",
    "1. Sélectionnez les colonnes utiles pour l'analyse\n",
    "2. Renommez les colonnes si nécessaire (noms clairs, sans espaces)\n",
    "3. Faites une vérification finale avec `info()` et `head()`\n",
    "4. Exportez en CSV : `catnat_clean.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539105f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**1. Sélectionnez les colonnes utiles pour l'analyse**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "86413332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DisNo.</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Decennie</th>\n",
       "      <th>Has_Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-0121-IDN</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-0524-USA</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>Americas</td>\n",
       "      <td>United States Of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-0281-SLB</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Tropical cylone Raquel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-0274-KHM</td>\n",
       "      <td>Epidemic</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>Dengue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-0275-JPN</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Japon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DisNo. Disaster Type    Region                   Country  \\\n",
       "0  2020-0121-IDN         Flood      Asia                 Indonesia   \n",
       "1  2008-0524-USA      Wildfire  Americas  United States Of America   \n",
       "2  2015-0281-SLB         Storm   Oceania           Solomon Islands   \n",
       "3  2007-0274-KHM      Epidemic      Asia                  Cambodia   \n",
       "4  2008-0275-JPN    Earthquake      Asia                     Japon   \n",
       "\n",
       "   Total Deaths  Start Year              Event Name  Magnitude  Decennie  \\\n",
       "0           1.0        2020                     NaN        NaN      2020   \n",
       "1           NaN        2008                     NaN        NaN      2000   \n",
       "2           9.0        2015  Tropical cylone Raquel        NaN      2010   \n",
       "3         182.0        2007                  Dengue        NaN      2000   \n",
       "4           1.0        2008                     NaN        6.8      2000   \n",
       "\n",
       "   Has_Deaths  \n",
       "0        True  \n",
       "1       False  \n",
       "2        True  \n",
       "3        True  \n",
       "4        True  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_export = df[['DisNo.', 'Disaster Type', 'Region', 'Country', \n",
    "               'Total Deaths', 'Start Year', 'Event Name', 'Magnitude', \n",
    "               'Decennie', 'Has_Deaths']]\n",
    "df_export.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee5d79f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**2. Renommez les colonnes si nécessaire (noms clairs, sans espaces)**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cd76cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export = df_export.rename(columns={\n",
    "    'DisNo.': 'ID_Catastrophe',\n",
    "    'Disaster Type': 'Type_Catastrophe',\n",
    "    'Start Year': 'Annee_Debut',\n",
    "    'Event Name': 'Nom_Evenement',\n",
    "    'Total Deaths': 'Nombre_Deces',\n",
    "    'Has_Deaths': 'A_Des_Deces',\n",
    "    'Country': 'Pays'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a8cde9",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**3. Faites une vérification finale avec `info()` et `head()`**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e8dfed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informations sur le dataset :\n",
      "<class 'pandas.DataFrame'>\n",
      "Index: 17014 entries, 0 to 17509\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   ID_Catastrophe    17014 non-null  str    \n",
      " 1   Type_Catastrophe  17014 non-null  str    \n",
      " 2   Region            17014 non-null  str    \n",
      " 3   Pays              17014 non-null  str    \n",
      " 4   Nombre_Deces      12175 non-null  float64\n",
      " 5   Annee_Debut       17014 non-null  int64  \n",
      " 6   Nom_Evenement     3875 non-null   str    \n",
      " 7   Magnitude         1721 non-null   float64\n",
      " 8   Decennie          17014 non-null  int64  \n",
      " 9   A_Des_Deces       17014 non-null  bool   \n",
      "dtypes: bool(1), float64(2), int64(2), str(5)\n",
      "memory usage: 1.3 MB\n",
      "\n",
      "\n",
      "\n",
      "Premiers enregistrements :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Catastrophe</th>\n",
       "      <th>Type_Catastrophe</th>\n",
       "      <th>Region</th>\n",
       "      <th>Pays</th>\n",
       "      <th>Nombre_Deces</th>\n",
       "      <th>Annee_Debut</th>\n",
       "      <th>Nom_Evenement</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Decennie</th>\n",
       "      <th>A_Des_Deces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-0121-IDN</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-0524-USA</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>Americas</td>\n",
       "      <td>United States Of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-0281-SLB</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Tropical cylone Raquel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-0274-KHM</td>\n",
       "      <td>Epidemic</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>Dengue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-0275-JPN</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Japon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_Catastrophe Type_Catastrophe    Region                      Pays  \\\n",
       "0  2020-0121-IDN            Flood      Asia                 Indonesia   \n",
       "1  2008-0524-USA         Wildfire  Americas  United States Of America   \n",
       "2  2015-0281-SLB            Storm   Oceania           Solomon Islands   \n",
       "3  2007-0274-KHM         Epidemic      Asia                  Cambodia   \n",
       "4  2008-0275-JPN       Earthquake      Asia                     Japon   \n",
       "\n",
       "   Nombre_Deces  Annee_Debut           Nom_Evenement  Magnitude  Decennie  \\\n",
       "0           1.0         2020                     NaN        NaN      2020   \n",
       "1           NaN         2008                     NaN        NaN      2000   \n",
       "2           9.0         2015  Tropical cylone Raquel        NaN      2010   \n",
       "3         182.0         2007                  Dengue        NaN      2000   \n",
       "4           1.0         2008                     NaN        6.8      2000   \n",
       "\n",
       "   A_Des_Deces  \n",
       "0         True  \n",
       "1        False  \n",
       "2         True  \n",
       "3         True  \n",
       "4         True  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Informations sur le dataset :\")\n",
    "df_export.info()\n",
    "\n",
    "print(\"\\n\\n\\nPremiers enregistrements :\")\n",
    "df_export.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670725ef",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "#### __**4. Exportez en CSV : `catnat_clean.csv`**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7acd33eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fichier 'data/processed/catnat_clean_2.0.csv' exporté avec succès !\n"
     ]
    }
   ],
   "source": [
    "output_path = \"data/processed/catnat_clean_2.0.csv\"\n",
    "\n",
    "df_export.to_csv(output_path, index=False)\n",
    "print(f\"\\nFichier '{output_path}' exporté avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bee7f3",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "\n",
    "## __**Exercice 9 — Vérification dans Tableau**__\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Tableau Public :**\n",
    "https://public.tableau.com/app/profile/jeathusan.kugathas/viz/NettoyageetAnalyse-DonnesdeCatastrophes/Localisationgographiquedescatastrophes\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## __*À faire*__\n",
    "\n",
    "1. Ouvrez Tableau Public\n",
    "2. Connectez-vous au fichier `catnat_clean.csv`\n",
    "3. Vérifiez dans l'écran \"Source de données\" :\n",
    "   - Les types sont-ils corrects ? (# pour nombres, Abc pour texte)\n",
    "   - Les nombres sont-ils bien reconnus ?\n",
    "4. Créez un bar chart : `Type_Catastrophe` vs `COUNT(ID_Catastrophe)`\n",
    "   - Les catégories sont-elles propres ? (pas de doublons)\n",
    "5. Créez un bar chart : `Region` vs `SUM(Deces)`\n",
    "   - Les 5 régions sont-elles bien distinctes ?\n",
    "6. Créez une carte avec `Country`\n",
    "   - Les pays sont-ils reconnus ?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
